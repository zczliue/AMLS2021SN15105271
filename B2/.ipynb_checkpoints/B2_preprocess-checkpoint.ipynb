{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import math\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import B2_lab2landmarks_rewrite as B2_lab2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the parameters for Grid search\n",
    "split_ratio = 0.75\n",
    "cvfold = 5\n",
    "\n",
    "\n",
    "\n",
    "#SVM\n",
    "SVM_tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2],'C': [1,10]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "                        {'kernel':['poly'],'gamma': [1e-2],'degree':[3]}]\n",
    "\n",
    "#SVM_tuned_parameters = [{'kernel': ['linear'], 'C': [1, 10]}]\n",
    "\n",
    "#Logistic Regression\n",
    "#LogReg_tuned_parameters = [{ 'solver':['lbfgs']}, #L2\n",
    "#                           {'solver':['liblinear'], 'penalty':['l1']}] #L1\n",
    "LogReg_tuned_parameters = [{ 'solver':['lbfgs']}]\n",
    "\n",
    "#Random Forest\n",
    "#RF_tuned_parameters = [{'n_estimators':[10, 50], 'max_depth':[1,5], 'min_samples_split':[500, 1000]}]\n",
    "RF_tuned_parameters = [{'n_estimators':[10, 50], 'max_depth':[50, 100]}]\n",
    "\n",
    "#KNN parameter\n",
    "KNN_tuned_parameters = [{'n_neighbors':[25, 50, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the dictionary contains dlib's 68-point facial landmark detector:\n",
    "# copyright: https://github.com/jrosebr1/imutils/blob/master/imutils/face_utils/helpers.py\n",
    "FACIAL_LANDMARKS_68_IDXS = OrderedDict([\n",
    "\t(\"mouth\", (48, 68)),\n",
    "\t(\"inner_mouth\", (60, 68)),\n",
    "\t(\"right_eyebrow\", (17, 22)),\n",
    "\t(\"left_eyebrow\", (22, 27)),\n",
    "\t(\"right_eye\", (36, 41)),\n",
    "\t(\"left_eye\", (42, 47)),\n",
    "\t(\"nose\", (27, 36)),\n",
    "\t(\"jaw\", (0, 17))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#n_colors is the number of dominant colours to be detected in the image, used in cv.kmeans\n",
    "n_colors = 5\n",
    "roi_margin = 20 #pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_features, label_contents, no_features_sets, identified_file_sets, dominant_rgbs  = B2_lab2.extract_features_labels_and_dominant_colour(\"cartoon_set\", \"eye_color\", roi_margin, n_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, split_ratio):\n",
    "\n",
    "    #X, y,  = lab2.extract_features_labels(image_folder, label_name)\n",
    "    Y = np.array([y, -(y - 1)]).T\n",
    "    \n",
    "    X, Y = shuffle(X,Y)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, train_size=split_ratio)\n",
    "    \n",
    "    #print(train_X.shape) - > num of samples, 3 (RGB value)\n",
    "    #there is no need to reshape the dimension \n",
    "    #tr_X = train_X.reshape((train_X.shape[0], train_X.shape[1]*2))\n",
    "    #te_X = test_X.reshape((test_X.shape[0], test_X.shape[1]*2))\n",
    "    tr_X = train_X\n",
    "    te_X = test_X\n",
    "    \n",
    "    tr_Y = list(zip(*train_Y))[0]\n",
    "    te_Y = list(zip(*test_Y))[0]\n",
    "\n",
    "    return tr_X, te_X, tr_Y, te_Y \n",
    "\n",
    "\n",
    "def bulk_runtime_estimation(classifier, xtest):\n",
    "    \n",
    "    nsamp = xtest.shape[0]\n",
    "    start = time.time()\n",
    "    ypred = classifier.predict(xtest)\n",
    "    bulk_runtime = time.time() - start\n",
    "    \n",
    "    #average runtime per instance\n",
    "    avg_runtime = bulk_runtime/nsamp\n",
    "    \n",
    "    return ypred, bulk_runtime, avg_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Prediction with Grid Search Cross validation Logistic Regression\n",
    "# Compare between L1 or L2 regularization\n",
    "def LogReg_GridSearch_PredictionCV(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold):\n",
    "    clf = GridSearchCV(LogisticRegression(max_iter=5000), tuning_parameters, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search Logistic Regression Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    \n",
    "    #return classifier\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Prediction with Grid search SVC Cross validation\n",
    "def SVC_GridSearch_PredictionCV(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold):\n",
    "    # classifier\n",
    "    clf = GridSearchCV(SVC(), tuning_parameters, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search SVC Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    \n",
    "    #return classifier\n",
    "    return clf\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RF_GridSearch_PredictionCV(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold):\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifier() , tuning_parameters, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search Random Forest Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    \n",
    "    #return classifier\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KNN_Grid_search_Prediction_CV(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold):\n",
    "    clf = GridSearchCV(KNeighborsClassifier() , tuning_parameters, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search KNN Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    \n",
    "    #return classifier\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_ROC_curve(ytrue, ypred):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(ytrue, ypred) \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X, te_X, tr_Y, te_Y = split_data(dominant_rgbs, label_contents, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------\n",
      "Prediction with Grid search SVC Cross validation:\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.843 (+/-0.015) for {'C': 1, 'kernel': 'linear'}\n",
      "0.842 (+/-0.016) for {'C': 10, 'kernel': 'linear'}\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-52259a38fa12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# SVM result:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSVMclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC_GridSearch_PredictionCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM_tuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-e12bbcb18119>\u001b[0m in \u001b[0;36mSVC_GridSearch_PredictionCV\u001b[0;34m(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#ytrue, ypred = ytest, clf.predict(xtest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbulk_runtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_runtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbulk_runtime_estimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mytrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-3da3b12e1db9>\u001b[0m in \u001b[0;36mbulk_runtime_estimation\u001b[0;34m(classifier, xtest)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnsamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mbulk_runtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# SVM result:\n",
    "SVMclf = SVC_GridSearch_PredictionCV(tr_X, tr_Y, te_X, te_Y, SVM_tuned_parameters, cvfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------\n",
      "Prediction with Grid search Random Forest Cross validation:\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 50, 'n_estimators': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.867 (+/-0.012) for {'max_depth': 50, 'n_estimators': 10}\n",
      "0.863 (+/-0.012) for {'max_depth': 50, 'n_estimators': 50}\n",
      "0.865 (+/-0.009) for {'max_depth': 100, 'n_estimators': 10}\n",
      "0.867 (+/-0.014) for {'max_depth': 100, 'n_estimators': 50}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       392\n",
      "           1       0.90      0.87      0.88       405\n",
      "           2       0.87      0.84      0.86       410\n",
      "           3       0.91      0.86      0.88       421\n",
      "           4       0.78      0.89      0.83       395\n",
      "\n",
      "    accuracy                           0.86      2023\n",
      "   macro avg       0.87      0.86      0.86      2023\n",
      "weighted avg       0.87      0.86      0.87      2023\n",
      "\n",
      "Accuracy: 0.8645575877409788\n",
      "\n",
      "Average runtime per test instance: 2.3643863242390248e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Random Forest result:\n",
    "RFclf = RF_GridSearch_PredictionCV(tr_X, tr_Y, te_X, te_Y, RF_tuned_parameters, cvfold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------\n",
      "Prediction with Grid search KNN Cross validation:\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 25}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.845 (+/-0.020) for {'n_neighbors': 25}\n",
      "0.837 (+/-0.017) for {'n_neighbors': 50}\n",
      "0.837 (+/-0.024) for {'n_neighbors': 100}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       392\n",
      "           1       0.84      0.83      0.84       405\n",
      "           2       0.96      0.80      0.87       410\n",
      "           3       0.85      0.86      0.85       421\n",
      "           4       0.76      0.87      0.81       395\n",
      "\n",
      "    accuracy                           0.84      2023\n",
      "   macro avg       0.85      0.84      0.84      2023\n",
      "weighted avg       0.85      0.84      0.84      2023\n",
      "\n",
      "Accuracy: 0.8423133959466139\n",
      "\n",
      "Average runtime per test instance: 3.173807382701472e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNN result:\n",
    "KNNclf = KNN_Grid_search_Prediction_CV(tr_X, tr_Y, te_X, te_Y, KNN_tuned_parameters, cvfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
