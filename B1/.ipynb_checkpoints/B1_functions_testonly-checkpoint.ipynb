{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is test only\n",
    "\n",
    "## Need to change into larger Dataset\n",
    "\n",
    "# Assumptions: Face shape detection only requires shape of jawline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "##################################################################\n",
    "import B1_lab2landmarks_rewrite_testonly as B1_lab2\n",
    "##################################################################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "# This function is rewritten as follows:\n",
    "# the input image_folder must be a string that specifies 'celeba' or 'cartoon_set'\n",
    "# the input label_name must be a string that specifies the feature name, i.e. 'gender', 'smiling' as in labels.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the parameters for Grid search\n",
    "split_ratio = 0.75\n",
    "cvfold = 5\n",
    "\n",
    "#SVM_tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2],'C': [1]},\n",
    "#                        {'kernel': ['linear'], 'C': [1]}]\n",
    "SVM_tuned_parameters = [{'kernel': ['linear'], 'C': [1]}]\n",
    "\n",
    "#Random Forest\n",
    "#RF_tuned_parameters = [{'n_estimators':[10, 50], 'max_depth':[1,5], 'min_samples_split':[500, 1000]}]\n",
    "RF_tuned_parameters = [{'n_estimators':[10], 'max_depth':[5, 10]}]\n",
    "\n",
    "\n",
    "#KNN parameter\n",
    "KNN_tuned_parameters = [{'n_neighbors':[100, 500, 1000]}]\n",
    "\n",
    "MLP_tuned_parameters = [{'hidden_layer_sizes': [(100,100,100), (100,200,100), (100,)], \n",
    "                         'activation': ['logistic', 'tanh', 'relu'],\n",
    "                         'learning_rate':['constant', 'adaptive']}]\n",
    "\n",
    "\n",
    "#\n",
    "Squential_model_parameters = {'num_hidden_layer': 3,\n",
    "                              'hidden_layer_activation' : ['relu','tanh','relu'],\n",
    "                              'dropout':[0.5,0.25,0.125],\n",
    "                              'last_activation':'softmax',\n",
    "                              'batch_size':1000}\n",
    "\n",
    "#Squential_gridsearch_params = {'batch_size' : [1000, 2000]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, split_ratio):\n",
    "\n",
    "    #print('----------------------------------------------------')\n",
    "    #print(Y)\n",
    "\n",
    "    X, Y = shuffle(X,Y)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, train_size=split_ratio)\n",
    "    \n",
    "    #reshape into appropriate dimensions\n",
    "    tr_X = train_X.reshape((train_X.shape[0], train_X.shape[1]*2))\n",
    "    te_X = test_X.reshape((test_X.shape[0], test_X.shape[1]*2))\n",
    "    \n",
    "    \n",
    "    #convert Y to binary class matrices\n",
    "    #tr_Y = list(zip(*train_Y))[0]\n",
    "    #te_Y = list(zip(*test_Y))[0]\n",
    "    tr_Y = train_Y\n",
    "    te_Y = test_Y\n",
    "    \n",
    "    #number of unique values\n",
    "    #tr_class_values, tr_num_classes = np.unique(tr_Y, return_counts=True)\n",
    "    #te_class_values, te_num_classes = np.unique(te_Y, return_counts=True)\n",
    "    \n",
    "    tr_Y = keras.utils.to_categorical(tr_Y)\n",
    "    te_Y = keras.utils.to_categorical(te_Y)\n",
    "\n",
    "    #print('----------------------------------------------------')\n",
    "    #print(tr_Y)\n",
    "    return tr_X, te_X, tr_Y, te_Y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_runtime_estimation(classifier, xtest):\n",
    "    \n",
    "    nsamp = xtest.shape[0]\n",
    "    start = time.time()\n",
    "    ypred = classifier.predict(xtest)\n",
    "    bulk_runtime = time.time() - start\n",
    "    \n",
    "    #average runtime per instance\n",
    "    avg_runtime = bulk_runtime/nsamp\n",
    "    \n",
    "    return ypred, bulk_runtime, avg_runtime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Prediction with Grid search SVC Cross validation\n",
    "def SVC_GridSearch_PredictionCV(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold):\n",
    "    # classifier\n",
    "    clf = GridSearchCV(SVC(decision_function_shape='ovo'), tuning_parameters, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search SVC Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    print()\n",
    "    print(ypred[0:20])\n",
    "\n",
    "\n",
    "    #return classifier\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_GridSearch_PredictionCV(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold):\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifier() , tuning_parameters, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search Random Forest Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    \n",
    "    #return classifier\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KNN_Grid_search_Prediction_CV(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold):\n",
    "    clf = GridSearchCV(KNeighborsClassifier() , tuning_parameters, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search KNN Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    \n",
    "    #return classifier\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_Grid_search_Prediction_CV(xtrain, ytrain, xtest, ytest, tuning_parameters, cvfold):\n",
    "    scaler = StandardScaler() \n",
    "    scaler.fit(xtrain) \n",
    "    xtrain = scaler.transform(xtrain)\n",
    "    xtest = scaler.transform(xtest)\n",
    "    \n",
    "    clf = GridSearchCV(MLPClassifier(max_iter=5000) , tuning_parameters, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search MLP Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    \n",
    "    #return classifier\n",
    "    return clf\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequential_Grid_searchCV(xtrain, ytrain, xtest, ytest, model_parameters, gridsearch_params, cvfold, num_class):\n",
    "    scaler = StandardScaler() \n",
    "    scaler.fit(xtrain) \n",
    "    xtrain = scaler.transform(xtrain)\n",
    "    xtest = scaler.transform(xtest)\n",
    "    \n",
    "    #input feature shape \n",
    "    in_feature_shape = xtrain.shape[1]\n",
    "    #number of class (labels)\n",
    "    num_labels = num_class\n",
    "    \n",
    "    model = design_sequential_model(model_parameters, in_feature_shape, num_class)\n",
    "\n",
    "\n",
    "    history = model.fit(xtrain, ytrain,\n",
    "                    batch_size=100,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(xtest, ytest))\n",
    "    score = model.evaluate(xtest, ytest, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #return classifier\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_sequential_model(params, inshape, num_class):\n",
    "    \n",
    "    model = Sequential()\n",
    "    num_hidden_layer = params['num_hidden_layer']\n",
    "    \n",
    "\n",
    "    # initial layer\n",
    "    # we use 2^(hiddenlayer +1) as the output number of neuron \n",
    "    model.add(Dense(inshape*pow(2, num_hidden_layer+1) , input_shape=(inshape,),\n",
    "                    activation='relu'))\n",
    "    \n",
    "    #If user has specify the output neuron at each hidden layer:\n",
    "    if \"hidden_neuron\" in params:\n",
    "        \n",
    "        # hidden layers\n",
    "        for i in range(num_hidden_layer):\n",
    "            print('Adding layer '+str(i+1)+':')\n",
    "        \n",
    "            model.add(Dense(params['hidden_neuron'][i], activation=params['hidden_layer_activation'][i]))\n",
    "            model.add(Dropout(params['dropout'][i]))\n",
    "            \n",
    "    \n",
    "    #default output neuron at each hidden layer: descending at base 2\n",
    "    else:\n",
    "                # hidden layers\n",
    "        for i in range(num_hidden_layer):\n",
    "            print('Adding layer '+str(i+1)+':')\n",
    "        \n",
    "            model.add(Dense(inshape*pow(2, num_hidden_layer - i), activation=params['hidden_layer_activation'][i]))\n",
    "            model.add(Dropout(params['dropout'][i]))\n",
    "            \n",
    "    \n",
    "    ## final layer\n",
    "    model.add(Dense(num_class, activation=params['last_activation']))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n",
    " \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "landmark_features, label_contents, no_features_sets = B1_lab2.extract_features_labels('cartoon_set', 'face_shape')\n",
    "jawline_landmarks = B1_lab2.get_jawline(landmark_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tr_X, te_X, tr_Y, te_Y = split_data(jawline_landmarks, label_contents, split_ratio)\n",
    "tr_X, te_X, tr_Y, te_Y = split_data(landmark_features, label_contents, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------\n",
      "Prediction with Grid search KNN Cross validation:\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.088 (+/-0.010) for {'n_neighbors': 100}\n",
      "0.002 (+/-0.004) for {'n_neighbors': 500}\n",
      "0.000 (+/-0.000) for {'n_neighbors': 1000}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/envs/AMLS/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.07      0.12       363\n",
      "           1       0.00      0.00      0.00       384\n",
      "           2       0.76      0.12      0.21       435\n",
      "           3       0.00      0.00      0.00       391\n",
      "           4       0.95      0.33      0.49       381\n",
      "\n",
      "   micro avg       0.89      0.10      0.18      1954\n",
      "   macro avg       0.53      0.10      0.16      1954\n",
      "weighted avg       0.53      0.10      0.16      1954\n",
      " samples avg       0.10      0.10      0.10      1954\n",
      "\n",
      "Accuracy: 0.10286591606960081\n",
      "\n",
      "Average runtime per test instance: 0.0015738890139326957\n"
     ]
    }
   ],
   "source": [
    "# SVM result:\n",
    "#SVMclf = SVC_GridSearch_PredictionCV(tr_X, tr_Y, te_X, te_Y, SVM_tuned_parameters, cvfold)\n",
    "\n",
    "\n",
    "# KNN result: \n",
    "KNNclf = KNN_Grid_search_Prediction_CV(tr_X, tr_Y, te_X, te_Y, KNN_tuned_parameters, cvfold)\n",
    "\n",
    "\n",
    "# Random Forest result\n",
    "#Rfclf = RF_GridSearch_PredictionCV(tr_X, tr_Y, te_X, te_Y, RF_tuned_parameters , cvfold)\n",
    "\n",
    "#MLP result\n",
    "MLP_clf = MLP_Grid_search_Prediction_CV(tr_X, tr_Y, te_X, te_Y, MLP_tuned_parameters, cvfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer 1:\n",
      "Adding layer 2:\n",
      "Adding layer 3:\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 2176)              298112    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1088)              2368576   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 544)               592416    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 544)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 272)               148240    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 272)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 5)                 1365      \n",
      "=================================================================\n",
      "Total params: 3,408,709\n",
      "Trainable params: 3,408,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5861 samples, validate on 1954 samples\n",
      "Epoch 1/20\n",
      "5861/5861 [==============================] - 9s 1ms/step - loss: 1.3726 - accuracy: 0.4600 - val_loss: 0.9779 - val_accuracy: 0.5967\n",
      "Epoch 2/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.9375 - accuracy: 0.6310 - val_loss: 0.7809 - val_accuracy: 0.6740\n",
      "Epoch 3/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.8245 - accuracy: 0.6830 - val_loss: 0.7848 - val_accuracy: 0.7057\n",
      "Epoch 4/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.7519 - accuracy: 0.7076 - val_loss: 0.7252 - val_accuracy: 0.7195\n",
      "Epoch 5/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.7089 - accuracy: 0.7274 - val_loss: 0.7858 - val_accuracy: 0.6842\n",
      "Epoch 6/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.6898 - accuracy: 0.7350 - val_loss: 0.6768 - val_accuracy: 0.7272\n",
      "Epoch 7/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.6503 - accuracy: 0.7500 - val_loss: 0.6661 - val_accuracy: 0.7318\n",
      "Epoch 8/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.6278 - accuracy: 0.7575 - val_loss: 0.6473 - val_accuracy: 0.7503\n",
      "Epoch 9/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.6135 - accuracy: 0.7683 - val_loss: 0.6540 - val_accuracy: 0.7375\n",
      "Epoch 10/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.5971 - accuracy: 0.7698 - val_loss: 0.5988 - val_accuracy: 0.7574\n",
      "Epoch 11/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.5740 - accuracy: 0.7780 - val_loss: 0.6911 - val_accuracy: 0.7339\n",
      "Epoch 12/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.5481 - accuracy: 0.7872 - val_loss: 0.6307 - val_accuracy: 0.7482\n",
      "Epoch 13/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.5428 - accuracy: 0.7900 - val_loss: 0.6519 - val_accuracy: 0.7625\n",
      "Epoch 14/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.5443 - accuracy: 0.7925 - val_loss: 0.6329 - val_accuracy: 0.7595\n",
      "Epoch 15/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.5295 - accuracy: 0.7997 - val_loss: 0.5920 - val_accuracy: 0.7866\n",
      "Epoch 16/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.5189 - accuracy: 0.8038 - val_loss: 0.6187 - val_accuracy: 0.7707\n",
      "Epoch 17/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.4932 - accuracy: 0.8092 - val_loss: 0.6590 - val_accuracy: 0.7456\n",
      "Epoch 18/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.4800 - accuracy: 0.8130 - val_loss: 0.6589 - val_accuracy: 0.7697\n",
      "Epoch 19/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.4895 - accuracy: 0.8099 - val_loss: 0.6236 - val_accuracy: 0.7707\n",
      "Epoch 20/20\n",
      "5861/5861 [==============================] - 7s 1ms/step - loss: 0.4701 - accuracy: 0.8224 - val_loss: 0.7887 - val_accuracy: 0.7385\n",
      "Test loss: 0.7887214738246484\n",
      "Test accuracy: 0.7384851574897766\n"
     ]
    }
   ],
   "source": [
    "#Squential result\n",
    "num_class = len(np.unique(label_contents))\n",
    "Squential_clf = Sequential_Grid_searchCV(tr_X, tr_Y, te_X, te_Y, Squential_model_parameters, Squential_gridsearch_params, cvfold, num_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer 1:\n",
      "Adding layer 2:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1088)              149056    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 544)               592416    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 544)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 272)               148240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 272)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 1365      \n",
      "=================================================================\n",
      "Total params: 891,077\n",
      "Trainable params: 891,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = KerasClassifier(build_fn = design_sequential_model,verbose=0, params = model_parameters, inshape = in_feature_shape, num_class = num_labels)\n",
    "    clf = GridSearchCV(estimator=model, param_grid=gridsearch_params, cv = cvfold)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Prediction with Grid search MLP Cross validation:\")\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    #ytrue, ypred = ytest, clf.predict(xtest)\n",
    "    ypred, bulk_runtime, avg_runtime = bulk_runtime_estimation(clf, xtest)\n",
    "    ytrue, ypred = ytest, ypred\n",
    "    \n",
    "    print(classification_report(ytrue, ypred))\n",
    "    print(\"Accuracy:\", accuracy_score(ytrue, ypred))\n",
    "    print()\n",
    "    print('Average runtime per test instance:', avg_runtime)\n",
    "    \n",
    "    #return classifier\n",
    "    return clf\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
